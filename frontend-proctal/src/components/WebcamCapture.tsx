import React, { useEffect, useRef, useState } from "react";
import Webcam from "react-webcam";
import axios, { AxiosResponse } from "axios";
import "./WebcamCapture.css";
import { useDispatch, useSelector } from "react-redux";
import { RootState } from "../redux/store";

import {
  setAlertMessage,
  setCapturedImage,
  incrementMalpractice,
  setIsTestCompleted,
  setMalpracticeCount,
} from "../redux/proctorSlice";

interface WebcamCaptureProps {
  onMalpracticeDetected: (message: string, imageUrl: string) => void;
  isTestStarted: boolean;
  isTestCompleted: boolean;
  onVerificationComplete: () => void;
  applicantId: string;
}

interface VerificationResponse {
  status:
    | "verified"
    | "identity_registered"
    | "face_not_detected"
    | "multiple_faces"
    | "mismatch"
    | "no_reference_face";
  message?: string;
}

interface MalpracticeResponse {
  malpracticeImageUrl: string;
}

const WebcamCapture: React.FC<WebcamCaptureProps> = ({
  onMalpracticeDetected,
  isTestStarted,
  isTestCompleted,
  onVerificationComplete,
  applicantId,
}) => {
  const webcamRef = useRef<Webcam>(null);
  const [canCapture, setCanCapture] = useState<boolean>(false);
  const [faceDetected, setFaceDetected] = useState<boolean>(false);
  const [verificationComplete, setVerificationComplete] =
    useState<boolean>(false);
  const [isLoading, setIsLoading] = useState<boolean>(false);
  const [multipleFacesDetected, setMultipleFacesDetected] =
    useState<boolean>(false);
  const [isDetectionPaused, setIsDetectionPaused] = useState<boolean>(false);
  const [cameraReady, setCameraReady] = useState<boolean>(false);
  const [lastAlertTime, setLastAlertTime] = useState<number>(0);
  const [faceDetectionStatus, setFaceDetectionStatus] = useState<
    "idle" | "detecting" | "verified"
  >("idle");
  const [faceVerifiedAlertShown, setFaceVerifiedAlertShown] =
    useState<boolean>(false);
  const [lastDetectionTime, setLastDetectionTime] = useState<number>(0);
  const detectionIntervalRef = useRef<NodeJS.Timeout | null>(null);

  const dispatch = useDispatch();

  const malpracticeCount = useSelector(
    (state: RootState) => state.proctor.malpracticeCount
  );

  // Check if webcam is accessible

  const handleUserMedia = (): void => {
    setCameraReady(true);
    dispatch(
      setAlertMessage(
        "‚úÖ Camera ready - Please position your face in the circle"
      )
    );
  };

  const handleUserMediaError = (): void => {
    setCameraReady(false);
    dispatch(setAlertMessage("üö´ Camera access denied or not available"));
  };

  // Rate-limited alert function
  const setRateLimitedAlert = (
    message: string,
    minInterval: number = 2000
  ): void => {
    const now = Date.now();
    if (now - lastAlertTime >= minInterval) {
      dispatch(setAlertMessage(message));
      setLastAlertTime(now);
    }
  };

  // Clear any ongoing intervals when component unmounts
  useEffect(() => {
    return () => {
      if (detectionIntervalRef.current) {
        clearInterval(detectionIntervalRef.current);
      }
    };
  }, []);

  // Instant face detection for user guidance (pre-verification)
  useEffect(() => {
    if (
      verificationComplete ||
      !webcamRef.current ||
      !applicantId ||
      !cameraReady
    )
      return;

    let animationFrameId: number;
    let lastCheckTime = 0;
    const CHECK_INTERVAL = 500;

    const checkFaceInstant = async (): Promise<void> => {
      const now = Date.now();
      if (now - lastCheckTime < CHECK_INTERVAL) {
        animationFrameId = requestAnimationFrame(checkFaceInstant);
        return;
      }
      lastCheckTime = now;

      try {
        if (!webcamRef.current || !webcamRef.current.video?.readyState) {
          animationFrameId = requestAnimationFrame(checkFaceInstant);
          return;
        }

        const imageSrc = webcamRef.current.getScreenshot();
        if (!imageSrc) {
          animationFrameId = requestAnimationFrame(checkFaceInstant);
          return;
        }

        const blob = await (await fetch(imageSrc)).blob();
        const file = new File([blob], "face_check.jpg", { type: blob.type });

        const formData = new FormData();
        formData.append("file", file);
        formData.append("applicant_id", applicantId);

        setFaceDetectionStatus("detecting");
        const res = await axios.post<VerificationResponse>(
          "http://localhost:8000/verify",
          formData
        );

        if (res.data.status === "multiple_faces") {
          setMultipleFacesDetected(true);
          setFaceDetected(false);
          setCanCapture(false);
          setRateLimitedAlert(
            "‚ö†Ô∏è Multiple faces detected - only one person allowed"
          );
        } else if (res.data.status === "face_not_detected") {
          setMultipleFacesDetected(false);
          setFaceDetected(false);
          setCanCapture(false);
          setRateLimitedAlert(
            "üö´ Face not detected - please position your face in the circle"
          );
        } else if (
          (res.data.status === "verified" ||
            res.data.status === "identity_registered") &&
          !verificationComplete
        ) {
          setMultipleFacesDetected(false);
          setFaceDetected(true);
          setCanCapture(true);
          setRateLimitedAlert("‚úÖ Face detected - ready for verification");
        }
        setFaceDetectionStatus("idle");
      } catch (error) {
        console.error("Instant face check error:", error);
        setFaceDetectionStatus("idle");
      }

      animationFrameId = requestAnimationFrame(checkFaceInstant);
    };

    checkFaceInstant();

    return () => {
      cancelAnimationFrame(animationFrameId);
    };
  }, [applicantId, verificationComplete, cameraReady]);

  // Live monitoring after verification
  useEffect(() => {
    if (!isTestStarted || isTestCompleted || !verificationComplete) {
      if (detectionIntervalRef.current) {
        clearInterval(detectionIntervalRef.current);
        detectionIntervalRef.current = null;
      }
      return;
    }

    const DETECTION_INTERVAL = 3000;

    const performDetection = async (): Promise<void> => {
      if (
        isDetectionPaused ||
        !webcamRef.current ||
        !webcamRef.current.video?.readyState
      )
        return;

      try {
        const now = Date.now();
        if (now - lastDetectionTime < DETECTION_INTERVAL) return;
        setLastDetectionTime(now);

        const imageSrc = webcamRef.current.getScreenshot();
        if (!imageSrc) return;

        const blob = await (await fetch(imageSrc)).blob();
        const file = new File([blob], "live.jpg", { type: blob.type });

        const formData = new FormData();
        formData.append("file", file);
        formData.append("applicant_id", applicantId);

        const res = await axios.post<VerificationResponse>(
          "http://localhost:8000/verify/embedding",
          formData
        );
        const status = res.data.status;

        switch (status) {
          case "verified":
            if (!faceVerifiedAlertShown) {
              setRateLimitedAlert("‚úÖ Face Verified");
              setFaceVerifiedAlertShown(true);
            }
            break;
          case "mismatch":
            await handleMalpractice("Face Mismatch Detected");
            break;
          case "face_not_detected":
            await handleMalpractice("Face not detected");
            break;
          case "multiple_faces":
            await handleMalpractice("Multiple faces detected");
            break;
          case "no_reference_face":
            setRateLimitedAlert("‚ÑπÔ∏è Please register your face first.");
            break;
        }
      } catch (err) {
        console.error("Live detection error:", err);
      }
    };

    // Clear any existing interval
    if (detectionIntervalRef.current) {
      clearInterval(detectionIntervalRef.current);
    }

    // Start new interval
    detectionIntervalRef.current = setInterval(
      performDetection,
      DETECTION_INTERVAL
    );

    return () => {
      if (detectionIntervalRef.current) {
        clearInterval(detectionIntervalRef.current);
      }
    };
  }, [
    isTestStarted,
    isTestCompleted,
    verificationComplete,
    applicantId,
    isDetectionPaused,
    lastDetectionTime,
    faceVerifiedAlertShown,
  ]);

  const handleMalpractice = async (message: string): Promise<void> => {
    setIsDetectionPaused(true);
    setFaceVerifiedAlertShown(false);
    setRateLimitedAlert(`‚ö†Ô∏è ${message}`);

    try {
      await captureAndReportMalpractice(message);
    } catch (error) {
      console.error("Error handling malpractice:", error);
    }

    setTimeout(() => {
      setIsDetectionPaused(false);
    }, 2000);
  };

  const captureAndReportMalpractice = async (
    message: string
  ): Promise<void> => {
    try {
      if (!webcamRef.current) return;

      const imageSrc = webcamRef.current.getScreenshot();
      if (!imageSrc) return;

      const blob = await (await fetch(imageSrc)).blob();
      const file = new File([blob], "malpractice.jpg", { type: blob.type });

      const formData = new FormData();
      formData.append("file", file);
      formData.append("alertMessage", message);
      formData.append("applicantId", applicantId);

      const res = await axios.post<MalpracticeResponse>(
        "http://localhost:3000/malpractice/alert",
        formData,
        {
          headers: {
            "Content-Type": "multipart/form-data",
          },
        }
      );

      onMalpracticeDetected(message, res.data.malpracticeImageUrl);
      dispatch(incrementMalpractice());
      const newCount = malpracticeCount + 1;
      if (newCount >= 5) {
        dispatch(
          setAlertMessage("‚ùå Test terminated due to multiple malpractices.")
        );
        dispatch(setIsTestCompleted(true));
        setTimeout(() => {
          window.location.href = "about:blank";
        }, 10000);
      }
    } catch (error) {
      console.error(
        "Error reporting malpractice:",
        axios.isAxiosError(error)
          ? error.response?.data || error.message
          : error
      );
      setRateLimitedAlert("‚ö†Ô∏è Failed to report malpractice");
      throw error;
    }
  };

  const registerCandidate = async (imageSrc: string): Promise<any> => {
    try {
      if (!imageSrc) throw new Error("No image captured");

      const blob = await (await fetch(imageSrc)).blob();
      const file = new File([blob], "profile.jpg", { type: blob.type });

      const formData = new FormData();
      formData.append("file", file);
      formData.append("applicantId", applicantId);

      const response = await axios.post(
        "http://localhost:3000/malpractice/register-candidate",
        formData,
        {
          headers: {
            "Content-Type": "multipart/form-data",
          },
          withCredentials: true,
        }
      );
      return response.data;
    } catch (error) {
      console.error("Registration failed:", error);
      throw error;
    }
  };

  const verifyIdentity = async (
    imageSrc: string
  ): Promise<AxiosResponse<VerificationResponse>> => {
    try {
      if (!imageSrc) throw new Error("No image captured");

      const blob = await (await fetch(imageSrc)).blob();
      const file = new File([blob], "verify.jpg", { type: blob.type });

      const formData = new FormData();
      formData.append("file", file);
      formData.append("applicant_id", applicantId);

      return await axios.post<VerificationResponse>(
        "http://localhost:8000/verify",
        formData,
        {
          headers: {
            "Content-Type": "multipart/form-data",
          },
        }
      );
    } catch (error) {
      console.error("Verification error:", error);
      throw error;
    }
  };

  const capture = async (): Promise<void> => {
    if (!canCapture || !applicantId || !webcamRef.current) {
      setRateLimitedAlert(
        "üö´ Cannot capture ‚Äì No valid face detected or missing user ID"
      );
      return;
    }

    setIsLoading(true);
    setRateLimitedAlert("‚è≥ Verifying your identity...");

    try {
      const imageSrc = webcamRef.current.getScreenshot();
      if (!imageSrc) throw new Error("Failed to capture image");

      // Register candidate first
      await registerCandidate(imageSrc);

      // Then verify identity
      const verifyResponse = await verifyIdentity(imageSrc);
      const status = verifyResponse.data.status;

      let message = "";
      switch (status) {
        case "face_not_detected":
          message = "üö´ Face not detected ‚Äì please look at the camera.";
          break;
        case "multiple_faces":
          message = "‚ö†Ô∏è Multiple faces detected ‚Äì only one person allowed.";
          break;
        case "mismatch":
          message = "‚ùå Face mismatch ‚Äì identity verification failed.";
          break;
        case "identity_registered":
        case "verified":
          message = "‚úÖ Identity verified successfully.";
          setVerificationComplete(true);
          dispatch(setCapturedImage(imageSrc));
          onVerificationComplete();
          setFaceVerifiedAlertShown(false); // Reset to show new alert
          break;
        default:
          message = "‚ùó Unknown verification response.";
      }

      setRateLimitedAlert(message);
    } catch (error) {
      console.error("Error during verification:", error);
      setRateLimitedAlert(
        `‚ùå Error: ${
          axios.isAxiosError(error)
            ? error.response?.data?.message || error.message
            : error
        }`
      );
    } finally {
      setIsLoading(false);
    }
  };

  // Get border color based on detection status
  const getBorderColor = (): string => {
    if (!cameraReady) return "#9E9E9E";
    if (multipleFacesDetected) return "#FF5722";
    if (faceDetected) return "#4CAF50";
    return "#F44336";
  };

  // Get button text based on state
  const getButtonText = (): string => {
    if (isLoading) return "Processing...";
    if (!cameraReady) return "Camera Not Available";
    if (faceDetected) return "Capture & Verify Identity";
    return "Face Not Detected";
  };

  return (
    <div className="webcam-container">
      <div
        className={`webcam-wrapper ${cameraReady ? "ready" : ""}`}
        style={{
          borderColor: getBorderColor(),
          boxShadow: `0 0 20px ${getBorderColor()}80`,
        }}
      >
        {!cameraReady && (
          <div className="loading-overlay">Loading camera...</div>
        )}
        <Webcam
          ref={webcamRef}
          className={`webcam ${cameraReady ? "show" : "hide"}`}
          screenshotFormat="image/jpeg"
          width={300}
          height={300}
          videoConstraints={{
            width: 640,
            height: 480,
            facingMode: "user",
          }}
          onUserMedia={handleUserMedia}
          onUserMediaError={handleUserMediaError}
        />
      </div>

      {!verificationComplete && (
        <button
          className={`capture-button ${
            canCapture && !isLoading ? "active" : "disabled"
          }`}
          style={{
            opacity: isLoading ? 0.7 : 1,
            transform: canCapture && !isLoading ? "scale(1)" : "scale(0.98)",
          }}
          onClick={capture}
          disabled={!canCapture || isLoading || !cameraReady}
        >
          {getButtonText()}
        </button>
      )}
    </div>
  );
};

export default WebcamCapture;
